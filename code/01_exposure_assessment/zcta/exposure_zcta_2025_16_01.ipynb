{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import contextily as cx\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "root_dir = Path(\"~/Desktop/Desktop/epidemiology_PhD/00_repos/\").expanduser()\n",
    "\n",
    "url = \"https://hub.arcgis.com/api/v3/datasets/025fb2ea05f14890b2b11573341b5b18_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1\"\n",
    "\n",
    "output_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data/calfire_boundaries\"\n",
    "data_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data\"\n",
    "\n",
    "so_cal_counties = [\"025\", \"029\", \"037\", \"065\", \"059\", \"071\", \"073\", \"083\", \"111\", \"079\"]\n",
    "\n",
    "crs = 26911\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline \n",
    "# goal: zcta exposure dataset with exposure (yes/no) based on various buffers (specified below) \n",
    "# steps:\n",
    "    # 1. download fires data\n",
    "    # 2. load census tract data\n",
    "    # 3. load wf boundary data\n",
    "    # 4. create merged fire polys (agg over days)\n",
    "    # 5. buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "    # 6. overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "    # 7. final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: download fires data\n",
    "\n",
    "# generate a filename with the current date\n",
    "filename = f\"data_{datetime.now().strftime('%Y_%m_%d')}.geojson\"\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful\n",
    "response.raise_for_status()  \n",
    "\n",
    "# Save\n",
    "with open(output_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 2-3: load and clean fires and cts data \n",
    "\n",
    "# data contains wf data going back to 2024 or 2023 \n",
    "# filter to dates since January 7th, 2025 and take out time\n",
    "fires = gpd.read_file(output_path).to_crs(epsg=crs)\n",
    "cts = gpd.read_file(data_dir / \"tl_2010_06_tract10.shp\").to_crs(epsg=crs)\n",
    "cts = cts[['geometry', 'GEOID10', 'COUNTYFP10']]\n",
    "cts = cts[cts['COUNTYFP10'].isin(so_cal_counties)]\n",
    "\n",
    "zctas = gpd.read_file(data_dir / \"tl_2020_us_zcta520.shp\").to_crs(epsg=crs)\n",
    "zctas = zctas[['geometry', 'ZCTA5CE20']].rename(columns={'ZCTA5CE20': 'zcta'})\n",
    "zctas_socal = gpd.sjoin(zctas, cts, how='inner', predicate='intersects')\n",
    "zctas_socal = zctas_socal.drop_duplicates(subset='zcta')\n",
    "\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.tz_convert('US/Pacific')\n",
    "fires = fires[fires['poly_DateCurrent'] > '2025-01-06']\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.date\n",
    "\n",
    "# fill in names for all fires \n",
    "fires[\"incident_name\"] = fires[\"incident_name\"].str.lower()\n",
    "fires['incident_name'].fillna(fires['mission'].str.split('-').str[2].str.lower(), inplace=True)\n",
    "\n",
    "# filter to only the cols we need\n",
    "# incident_name, poly_DateCurrent, geometry\n",
    "fires = fires[[\"incident_name\", \"poly_DateCurrent\", \"geometry\"]]\n",
    "\n",
    "# NOTE: there is one row that is called kenneth but has a poly that covers both pallisades and kenneth. from jan 9\n",
    "# leaving it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: create merged fire polys (agg over days)\n",
    "# step 5: buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "# step 6: overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "# step 7: final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km\n",
    "buffer_distances = [0.5, 1, 10, 20]\n",
    "buffers = [500, 1_000, 10_000, 20_000]\n",
    "\n",
    "# Create empty dictionary to store results\n",
    "zcta_exposures = {}\n",
    "# Create list to store summary table\n",
    "summary_data = []\n",
    "\n",
    "# For each buffer distance\n",
    "for dist, dist_km in zip(buffers, buffer_distances):\n",
    "    # Create buffer\n",
    "    buffered_fires = fires.geometry.buffer(dist)\n",
    "    \n",
    "    # Dissolve all fire buffers into single geometry\n",
    "    combined_buffer = buffered_fires.unary_union\n",
    "\n",
    "    # Count exposed tracts\n",
    "    exposed_zctas = zctas_socal[zctas_socal.geometry.intersects(combined_buffer)]\n",
    "    num_exposed = len(exposed_zctas)\n",
    "    print(f\"Buffer distance: {dist_km} km, Number of exposed ZCTAs: {num_exposed}\")\n",
    "\n",
    "    # Store in our list\n",
    "    summary_data.append({\n",
    "        'buffer_distance_km': dist_km,\n",
    "        'num_exposed_zctas': num_exposed\n",
    "    })\n",
    "        \n",
    "    # Store zctas for this buffer distance\n",
    "    zcta_exposures[f'exposed_{dist_km}buffer'] = exposed_zctas['zcta'].tolist()\n",
    "\n",
    "# Create final dataframe\n",
    "result_df = pd.DataFrame({'zcta': zctas_socal['zcta'].values})\n",
    "\n",
    "# Add exp cols\n",
    "for col in zcta_exposures.keys():\n",
    "    result_df[col] = result_df['zcta'].isin(zcta_exposures[col]).astype(int)\n",
    "\n",
    "# Create summary dataframe and list of unique zctas\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "unique_zctas = result_df['zcta'].unique() # delete ?\n",
    "\n",
    "# Write out data\n",
    "result_df.to_csv(data_dir / f\"zcta_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\", index=False)\n",
    "summary_df.to_csv(data_dir / f\"zcta_summary_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\", index=False)\n",
    "pd.DataFrame(unique_zctas, columns=['zcta']).to_csv(data_dir / f\"zctas_{datetime.now().strftime('%Y_%m_%d')}.csv\", index=False) # delete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add percents to joans summary file (denom = zips that overlap socal counties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
