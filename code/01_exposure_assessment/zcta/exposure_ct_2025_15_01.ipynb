{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import contextily as cx\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "root_dir = Path(\"~/Desktop/Desktop/epidemiology_PhD/00_repos/\").expanduser()\n",
    "\n",
    "url = \"https://hub.arcgis.com/api/v3/datasets/025fb2ea05f14890b2b11573341b5b18_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1\"\n",
    "\n",
    "output_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data/calfire_boundaries\"\n",
    "data_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data\"\n",
    "\n",
    "so_cal_counties = [\"025\", \"029\", \"037\", \"065\", \"059\", \"071\", \"073\", \"083\", \"111\", \"079\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline \n",
    "# goal: census tract daily dataset with 3 exposure cols for every day since 1/7: \n",
    "    # 1. is it fully overlapping with wf boundary? \n",
    "    # 2. is it partially overlapping with wf boundary?\n",
    "    # 3. is it within the 25km buffered wf boundary?\n",
    "# steps:\n",
    "    # 1. download fires data\n",
    "    # 2. load census tract data\n",
    "    # 3. load wf boundary data\n",
    "    # 4. create merged fire polys (agg over days)\n",
    "    # 5. buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "    # 6. overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "    # 7. final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: download fires data\n",
    "\n",
    "# generate a filename with the current date\n",
    "filename = f\"data_{datetime.now().strftime('%Y_%m_%d')}.geojson\"\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful\n",
    "response.raise_for_status()  \n",
    "\n",
    "# Save\n",
    "with open(output_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 2-3: load and clean fires and cts data \n",
    "\n",
    "# data contains wf data going back to 2024 or 2023 \n",
    "# filter to dates since January 7th, 2025 and take out time\n",
    "fires = gpd.read_file(output_path).to_crs(epsg=2229)\n",
    "cts = gpd.read_file(data_dir / \"tl_2010_06_tract10.shp\").to_crs(epsg=2229)\n",
    "cts = cts[['geometry', 'GEOID10', 'COUNTYFP10']]\n",
    "cts = cts[cts['COUNTYFP10'].isin(so_cal_counties)]\n",
    "\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.tz_convert('US/Pacific')\n",
    "fires = fires[fires['poly_DateCurrent'] > '2025-01-06']\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.date\n",
    "\n",
    "# fill in names for all fires \n",
    "fires[\"incident_name\"] = fires[\"incident_name\"].str.lower()\n",
    "fires['incident_name'].fillna(fires['mission'].str.split('-').str[2].str.lower(), inplace=True)\n",
    "\n",
    "# filter to only the cols we need\n",
    "# incident_name, poly_DateCurrent, geometry\n",
    "fires = fires[[\"incident_name\", \"poly_DateCurrent\", \"geometry\"]]\n",
    "\n",
    "# NOTE: there is one row that is called kenneth but has a poly that covers both pallisades and kenneth. from jan 9\n",
    "# leaving it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: create merged fire polys (agg over days)\n",
    "# step 5: buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "# step 6: overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "# step 7: final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km\n",
    "buffer_distances = [0.5, 1, 10, 20]\n",
    "buffers = [500, 1_000, 10_000, 20_000]\n",
    "\n",
    "# Create empty dictionary to store results\n",
    "tract_exposures = {}\n",
    "# Create list to store summary table\n",
    "summary_data = []\n",
    "\n",
    "# For each buffer distance\n",
    "for dist, dist_km in zip(buffers, buffer_distances):\n",
    "    # Create buffer\n",
    "    buffered_fires = fires.geometry.buffer(dist)\n",
    "    \n",
    "    # Dissolve all fire buffers into single geometry\n",
    "    combined_buffer = buffered_fires.unary_union\n",
    "\n",
    "    # Count exposed tracts\n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "    num_exposed = len(exposed_tracts)\n",
    "    \n",
    "    # Store in our list\n",
    "    summary_data.append({\n",
    "        'buffer_distance_km': dist_km,\n",
    "        'num_exposed_tracts': num_exposed\n",
    "    })\n",
    "    \n",
    "    # Spatial join with census tracts\n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "        \n",
    "    # Store tract GEOIDs for this buffer distance\n",
    "    tract_exposures[f'exposed_{dist_km}buffer'] = exposed_tracts['GEOID10'].tolist()\n",
    "\n",
    "# Create final dataframe\n",
    "result_df = pd.DataFrame({'GEOID10': cts['GEOID10']})\n",
    "result_df = result_df.set_index('GEOID10')\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Add exposure columns\n",
    "for col in tract_exposures.keys():\n",
    "    result_df[col] = result_df.index.isin(tract_exposures[col]).astype(int)\n",
    "\n",
    "# Write out data\n",
    "result_df.to_csv(data_dir / \"ct_exposures_2025_01_15.csv\")\n",
    "summary_df.to_csv(data_dir / \"ct_summary_exposures_2025_01_15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts[cts['COUNTYFP10']==\"037\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
