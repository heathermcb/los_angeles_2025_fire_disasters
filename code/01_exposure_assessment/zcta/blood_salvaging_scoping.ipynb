{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import contextily as ctx\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.patches import Patch\n",
    "from datetime import date\n",
    "\n",
    "root_dir = Path(\"~/Desktop/Desktop/epidemiology_PhD/00_repos/\").expanduser()\n",
    "\n",
    "data_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data\"\n",
    "\n",
    "so_cal_counties = [\"025\", \"029\", \"037\", \"065\", \"059\", \"071\", \"073\", \"083\", \"111\", \"079\"]\n",
    "\n",
    "crs = 26911\n",
    "\n",
    "def parse_datetime_string(date_str):\n",
    "    # split date and time\n",
    "    date_part = str(date_str)[:7]    # Gets '2025012'\n",
    "    \n",
    "    # parse date\n",
    "    year = date_part[:4]        # '2025'\n",
    "    day = date_part[5:]         # '012' -> '12'\n",
    "    month = '01'               # January\n",
    "    \n",
    "    # construct datetime string \n",
    "    datetime_str = f\"{year}-{month}-{day}\"\n",
    "    return pd.to_datetime(datetime_str)\n",
    "\n",
    "def remove_overlaps(smoke_df):\n",
    "    smoke_df = smoke_df.to_crs(epsg=3857)\n",
    "    \n",
    "    # split by density and make copies of the data\n",
    "    heavy = smoke_df[smoke_df['Density'] == 'Heavy'].copy()\n",
    "    medium = smoke_df[smoke_df['Density'] == 'Medium'].copy()\n",
    "    light = smoke_df[smoke_df['Density'] == 'Light'].copy()\n",
    "    \n",
    "    # lets split them up! \n",
    "    if not medium.empty and not heavy.empty:\n",
    "        medium['geometry'] = gpd.GeoSeries(\n",
    "            # remove heavy areas from medium\n",
    "            medium.geometry.apply(lambda x: x.difference(heavy.geometry.union_all())),\n",
    "            index=medium.index,\n",
    "            crs=medium.crs\n",
    "        )\n",
    "    \n",
    "    if not light.empty:\n",
    "        if not heavy.empty:\n",
    "            # remove heavy areas from light\n",
    "            light['geometry'] = gpd.GeoSeries(\n",
    "                light.geometry.apply(lambda x: x.difference(heavy.geometry.union_all())),\n",
    "                index=light.index,\n",
    "                crs=light.crs\n",
    "            )\n",
    "        if not medium.empty:\n",
    "            # remove medium areas\n",
    "            light['geometry'] = gpd.GeoSeries(\n",
    "                light.geometry.apply(lambda x: x.difference(medium.geometry.union_all())),\n",
    "                index=light.index,\n",
    "                crs=light.crs\n",
    "            )\n",
    "    \n",
    "    # come back together\n",
    "    return pd.concat([light, medium, heavy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal of this script: \n",
    "# KP wants to salvage blood samples from its catchment area\n",
    "# we want to: \n",
    "    # 1. identify the zip codes in the kaiser catchment area and determine their lead exposure status using cal enviro screen\n",
    "    # 2. determine smoke exposure by zip code\n",
    "    # 3. identify control zip codes that are and are not exposed to smoke and have similar lead exposure percentiles! matching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a. identify the zctas in the kp catchment area with geometries!\n",
    "\n",
    "# read in ca cts and subset to the so cal catchment area \n",
    "cts_ca = gpd.read_file(data_dir / \"00_raw/tl_2010_06_tract10.shp\")\n",
    "cts_kp = cts_ca[cts_ca['COUNTYFP10'].isin(so_cal_counties)]\n",
    "\n",
    "# read in zctas \n",
    "zctas_us = gpd.read_file(data_dir / \"00_raw/tl_2020_us_zcta520.shp\")\n",
    "\n",
    "# intersect zctas with the subsetted cts to get the zcta catchment area\n",
    "zctas_kp = gpd.sjoin(zctas_us, cts_kp, how=\"inner\", predicate=\"intersects\")\n",
    "zctas_kp = zctas_kp[[\"ZCTA5CE20\", \"geometry\"]].rename(columns={\"ZCTA5CE20\": \"zcta\"})\n",
    "zctas_kp = zctas_kp.dissolve(by='zcta', as_index=True)\n",
    "\n",
    "# where are they? \n",
    "zctas_kp.plot()\n",
    "\n",
    "# this plot shows nothing. need a lot more help to match this up to actual california places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is kaiser, where is so cal, where is california? \n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "zctas_kp = zctas_kp.to_crs(epsg=3857)\n",
    "zctas_kp.plot(ax=ax, alpha=0.5, edgecolor='black')\n",
    "\n",
    "# sos i have no idea where we are in ca\n",
    "\n",
    "# lets use a basemap with roads and california town and city labels. need all the help we can get.\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Voyager)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i cant find where things are in CA so lets read in fire boundaries to help match up to sat imagery! \n",
    "fire_boundaries = gpd.read_file(data_dir / \"00_raw/calfire_boundaries/data_2025_01_17.geojson\")\n",
    "fire_boundaries[\"poly_DateCurrent\"] = fire_boundaries[\"poly_DateCurrent\"].dt.tz_convert('US/Pacific')\n",
    "fire_boundaries = fire_boundaries[fire_boundaries['poly_DateCurrent'] > '2025-01-06']\n",
    "fire_boundaries[\"poly_DateCurrent\"] = fire_boundaries[\"poly_DateCurrent\"].dt.date\n",
    "\n",
    "# lets just pull palisades and eaton since those are the ones in the sat imagery and this is just for my own sanity\n",
    "fire_boundaries = fire_boundaries[fire_boundaries[\"incident_name\"].isin([\"Palisades\", \"Eaton\"])]\n",
    "\n",
    "# now lets add them to our plot! can we match up california images now? \n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "zctas_kp = zctas_kp.to_crs(epsg=3857)\n",
    "fire_boundaries = fire_boundaries.to_crs(epsg=3857)\n",
    "\n",
    "zctas_kp.plot(ax=ax, alpha=0.5, edgecolor='black')\n",
    "fire_boundaries.plot(ax=ax, alpha=1, edgecolor='red', facecolor=\"none\")\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Voyager)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# still no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b. pull in the lead exposure data so we can match on that later.\n",
    "    # going to use percentile and match on percentile bins (by 10 percentage pts)\n",
    "\n",
    "# read in data \n",
    "ces = pd.read_excel(data_dir / \"00_raw/calenviroscreen40resultsdatadictionary_F_2021.xlsx\")\n",
    "# NOTE: using cal enviro screen 4.0 for lead data and using lead percentile so it is a relative metric? \n",
    "    # https://oehha.ca.gov/calenviroscreen/download-data\n",
    "# NOTE: these data are at the CT level but are conveniently mapped to zctas \n",
    "    # if the same ZCTA is present in multiple rows, we'll take the mean of the values across rows for now\n",
    "\n",
    "\n",
    "ces_cols = [\"ZIP\", \"Lead\"]\n",
    "# NOTE: Joan, do you have a pref between using lead percentile and lead? see data dict for definitions\n",
    "ces = ces[ces_cols].rename(columns={\"ZIP\": \"zcta\", \"Lead\": \"lead\"})\n",
    "\n",
    "# some zip-cts have nas so drop those: \n",
    "ces = ces.dropna(subset=[\"zcta\", \"lead\"])\n",
    "\n",
    "# aggregate to zcta level\n",
    "ces = ces.groupby(\"zcta\").mean().reset_index()\n",
    "ces[\"zcta\"] = ces[\"zcta\"].astype(str).str.zfill(5)\n",
    "\n",
    "# subset ces data to kp zctas and merge them on: \n",
    "kp_ces = zctas_kp.merge(ces, on=\"zcta\")\n",
    "\n",
    "# make percentile bins for matching: \n",
    "kp_ces[\"lead_bin\"] = pd.qcut(kp_ces[\"lead\"], q=10, labels=False)\n",
    "\n",
    "# plot by lead bin\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "kp_ces = kp_ces.to_crs(epsg=3857)\n",
    "\n",
    "# Store the plot output\n",
    "plot = kp_ces.plot(ax=ax, alpha=0.5, edgecolor=None, column=\"lead\", legend=True)\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Voyager)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. clean up smoke data\n",
    "\n",
    "# read in smoke files for jan 7-12, 2025\n",
    "smoke_dir = data_dir / \"00_raw/smoke_plume\"\n",
    "smoke_files = list(smoke_dir.glob(\"*/*.shp\"))\n",
    "\n",
    "# read in all files and create a date var for each: \n",
    "smoke = pd.concat([gpd.read_file(f) for f in smoke_files])\n",
    "smoke[\"date\"] = smoke[\"Start\"].apply(parse_datetime_string)\n",
    "\n",
    "# subset to only the density, geometry, and date\n",
    "smoke = smoke[[\"date\", \"geometry\", \"Density\"]]\n",
    "\n",
    "# subset smoke to kp zctas\n",
    "smoke_kp = smoke.to_crs(epsg=3857)\n",
    "smoke_kp = gpd.sjoin(smoke_kp, zctas_kp, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "# dissolve by date and density\n",
    "smoke = smoke.dissolve(by=['date', 'Density'], as_index=True).reset_index()\n",
    "\n",
    "# convert back to gdf\n",
    "smoke = gpd.GeoDataFrame(smoke, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. map it! \n",
    "\n",
    "# colors\n",
    "okeefe = [\"#fbe3c2\", \"#f2c88f\", \"#ecb27d\", \"#e69c6b\", \"#d37750\", \"#b9563f\", \"#92351e\"]\n",
    "density_colors = {\n",
    "    'Light': okeefe[0],    # lightest\n",
    "    'Medium': okeefe[2],   # medium\n",
    "    'Heavy': okeefe[4]     # darkest\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(24, 4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# bounds of the entire dataset\n",
    "total_bounds = zctas_kp.total_bounds\n",
    "\n",
    "for i, date in enumerate(sorted(smoke[\"date\"].unique())):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    # subset to \n",
    "    smoke_date = smoke[smoke[\"date\"] == date]\n",
    "    \n",
    "    # remove overlaps so that we can get heavy on top! \n",
    "    smoke_date_no_overlap = remove_overlaps(smoke_date)\n",
    "    \n",
    "    # base map layers\n",
    "    kp_ces.plot(ax=ax, alpha=0.5, edgecolor=\"black\")\n",
    "    \n",
    "    # plot each density level separately\n",
    "    for density in ['Light', 'Medium', 'Heavy']:\n",
    "        density_data = smoke_date_no_overlap[smoke_date_no_overlap['Density'] == density]\n",
    "        if not density_data.empty:\n",
    "            density_data.plot(\n",
    "                ax=ax,\n",
    "                color=density_colors[density],\n",
    "                alpha=0.75,\n",
    "                edgecolor=None\n",
    "            )\n",
    "    \n",
    "    # manual legend\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=density_colors['Heavy'], label='Heavy', alpha=0.75),\n",
    "        Patch(facecolor=density_colors['Medium'], label='Medium', alpha=0.75),\n",
    "        Patch(facecolor=density_colors['Light'], label='Light', alpha=0.75)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Voyager)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(pd.to_datetime(date).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # set the same bounds for each subplot\n",
    "    ax.set_xlim(total_bounds[0], total_bounds[2])\n",
    "    ax.set_ylim(total_bounds[1], total_bounds[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "okeefe = [\"#fbe3c2\", \"#f2c88f\", \"#ecb27d\", \"#e69c6b\", \"#d37750\", \"#b9563f\", \"#92351e\"]\n",
    "density_colors = {\n",
    "    'Light': okeefe[0],    # lightest\n",
    "    'Medium': okeefe[2],   # medium\n",
    "    'Heavy': okeefe[4]     # darkest\n",
    "}\n",
    "\n",
    "# create figure with extra space at bottom for the lead legend\n",
    "fig, axs = plt.subplots(1, 6, figsize=(24, 5), constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "# bounds of the entire dataset\n",
    "total_bounds = zctas_kp.total_bounds\n",
    "\n",
    "# keep track of the lead plot for the legend\n",
    "lead_plot = None\n",
    "\n",
    "for i, date in enumerate(sorted(smoke[\"date\"].unique())):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    smoke_date = smoke[smoke[\"date\"] == date]\n",
    "    smoke_date_no_overlap = remove_overlaps(smoke_date)\n",
    "    \n",
    "    # base map layers - only show legend for lead in the last plot\n",
    "    lead_plot = kp_ces.plot(\n",
    "        ax=ax, \n",
    "        alpha=0.5, \n",
    "        edgecolor=None, \n",
    "        column=\"lead\", \n",
    "        legend=False  # Turn off individual legends\n",
    "    )\n",
    "    \n",
    "    # plot each density level separately\n",
    "    for density in ['Light', 'Medium', 'Heavy']:\n",
    "        density_data = smoke_date_no_overlap[smoke_date_no_overlap['Density'] == density]\n",
    "        if not density_data.empty:\n",
    "            density_data.plot(\n",
    "                ax=ax,\n",
    "                color=density_colors[density],\n",
    "                alpha=0.75,\n",
    "                edgecolor=None\n",
    "            )\n",
    "    \n",
    "    # manual legend for smoke\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=density_colors['Heavy'], label='Heavy', alpha=0.75),\n",
    "        Patch(facecolor=density_colors['Medium'], label='Medium', alpha=0.75),\n",
    "        Patch(facecolor=density_colors['Light'], label='Light', alpha=0.75)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Voyager)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(pd.to_datetime(date).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    ax.set_xlim(total_bounds[0], total_bounds[2])\n",
    "    ax.set_ylim(total_bounds[1], total_bounds[3])\n",
    "\n",
    "# manual legend for lead\n",
    "cax = fig.add_axes([0.3, 0.05, 0.4, 0.04])  # [left, bottom, width, height]\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=kp_ces['lead'].min(), vmax=kp_ces['lead'].max()))\n",
    "cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Lead Level', fontsize=10)\n",
    "cbar.set_label('Lead Level', fontsize=16)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c. \n",
    "#---------------------\n",
    "# first find all zctas exposed to heavy smoke at least once \n",
    "\n",
    "# find all zctas exposed to heavy smoke at least twice \n",
    "heavy_zcta_counts = smoke_kp[smoke_kp['Density'] == 'Heavy']['zcta'].value_counts()\n",
    "frequent_heavy_zctas = heavy_zcta_counts[heavy_zcta_counts >= 3].index.tolist()\n",
    "\n",
    "print(\"ZCTAs with heavy smoke at least twice:\", frequent_heavy_zctas)\n",
    "print(\"Count:\", len(frequent_heavy_zctas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d. \n",
    "#---------------------\n",
    "# second find all zctas exposed to no smoke ever \n",
    "\n",
    "# find all zctas exposed to no smoke ever by looking at which zctas in zctas_kp do not show up in smoke_kp\n",
    "zctas_with_smoke = smoke_kp['zcta'].unique()\n",
    "all_zctas = zctas_kp.reset_index(names = 'zcta')\n",
    "never_in_smoke = all_zctas[~all_zctas['zcta'].isin(zctas_with_smoke)]\n",
    "never_in_smoke\n",
    "\n",
    "print(\"\\nZCTAs never intersecting with smoke:\")\n",
    "print(never_in_smoke['zcta'].tolist())\n",
    "print(\"Count:\", len(never_in_smoke))\n",
    "\n",
    "#---------------------\n",
    "# merge on kp pop to make sure there are enough people \n",
    "pop = pd.read_csv(data_dir / \"00_raw/kpsc_zcta_counts.csv\")\n",
    "pop['zcta'] = pop['zcta'].astype(str).str.zfill(5)\n",
    "pop = pop.drop(columns = 'classification')\n",
    "\n",
    "# make a dataframe of all the zctas with heavy smoke and then all the zctas with no smoke and # of people in each\n",
    "heavy = pop[pop['zcta'].isin(frequent_heavy_zctas)]\n",
    "\n",
    "# make col that is 1 if heavy smoke and 0 if no smoke\n",
    "heavy['smoke'] = 1\n",
    "\n",
    "# make a dataframe of all zctas with no smoke and # of people in each\n",
    "no_smoke = pop[pop['zcta'].isin(never_in_smoke['zcta'])]\n",
    "no_smoke['smoke'] = 0\n",
    "\n",
    "# concat the 2 dataframes\n",
    "all = pd.concat([heavy, no_smoke])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \n",
    "# merge lead bins\n",
    "smoke_lead_zctas = all.merge(kp_ces, on=\"zcta\")\n",
    "\n",
    "# match cases (smoke=1) and controls (smoke=0) on lead bin\n",
    "smoke_lead_zctas = smoke_lead_zctas.sort_values(by=\"lead\")\n",
    "\n",
    "# get counts of cases/controls per lead_bin\n",
    "summary = (smoke_lead_zctas\n",
    "    .groupby(['lead_bin', 'smoke'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary.columns = ['lead_bin', 'no_smoke', 'heavy_smoke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final choices! \n",
    "#---------------------\n",
    "# lets pick the lead bins with the most overlap between no smoke and heavy smoke based on lead bin! those will be priority 1 \n",
    "priority_lead_bins = summary[summary['no_smoke'] > 0]\n",
    "priority_lead_bins = priority_lead_bins['lead_bin'].tolist()\n",
    "\n",
    "# if a zcta is a priority zcta, make it priority 1, otherwise priority 2. make priority col \n",
    "blood_sample_zctas = smoke_lead_zctas.copy()\n",
    "blood_sample_zctas['priority'] = 2\n",
    "blood_sample_zctas.loc[blood_sample_zctas['lead_bin'].isin(priority_lead_bins), 'priority'] = 1\n",
    "\n",
    "# drop geometry col so we can write out csvs \n",
    "blood_sample_zctas = blood_sample_zctas.drop(columns = 'geometry')\n",
    "\n",
    "# rename smoke to heavy smoke so it is more clear \n",
    "blood_sample_zctas = blood_sample_zctas.rename(columns = {'smoke': 'heavy_smoke'})\n",
    "blood_sample_zctas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out a csv of the zctas to sample blood from and the summary for joan\n",
    "# write out a csv of just zctas and priorities for kp \n",
    "blood_sample_zctas.to_csv(data_dir / \"01_intermediate/blood_sample_zctas.csv\", index=False)\n",
    "blood_sample_zctas[['zcta', 'priority']].to_csv(data_dir / \"01_intermediate/kp_blood_sample_zctas.csv\", index=False)\n",
    "summary.to_csv(data_dir / \"01_intermediate/blood_sample_zctas_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_lead_bin_summary(df):\n",
    "    \"\"\"\n",
    "    Creates a summary table of lead bins and their corresponding statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing 'lead' and 'lead_bin' columns\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with bin summary statistics\n",
    "    \"\"\"\n",
    "    # summary statistics for each bin\n",
    "    bin_summary = df.groupby('lead_bin').agg({\n",
    "        'lead': [\n",
    "            ('min', 'min'),\n",
    "            ('max', 'max'),\n",
    "            ('mean', 'mean'),\n",
    "            ('median', 'median'),\n",
    "            ('count', 'count')\n",
    "        ]\n",
    "    }).round(2)\n",
    "    \n",
    "    # flatten column names\n",
    "    bin_summary.columns = bin_summary.columns.get_level_values(1)\n",
    "    \n",
    "    # make lead_bin a column\n",
    "    bin_summary = bin_summary.reset_index()\n",
    "    \n",
    "    # add bin range column for easier interpretation\n",
    "    bin_summary['bin_range'] = bin_summary.apply(\n",
    "        lambda x: f\"{x['min']:.2f} - {x['max']:.2f}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # reorder columns\n",
    "    final_columns = ['lead_bin', 'bin_range', 'min', 'max', 'mean', 'median', 'count']\n",
    "    bin_summary = bin_summary[final_columns]\n",
    "    \n",
    "    return bin_summary\n",
    "\n",
    "# make summary\n",
    "lead_summary = create_lead_bin_summary(kp_ces)\n",
    "\n",
    "# save summary\n",
    "lead_summary.to_csv(data_dir / \"01_intermediate/lead_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
