{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import contextily as cx\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "root_dir = Path(\"~/Desktop/Desktop/epidemiology_PhD/00_repos/\").expanduser()\n",
    "\n",
    "url = \"https://hub.arcgis.com/api/v3/datasets/025fb2ea05f14890b2b11573341b5b18_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1\"\n",
    "\n",
    "output_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data/00_raw/calfire_boundaries\"\n",
    "data_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data\"\n",
    "\n",
    "so_cal_counties = [\"025\", \"029\", \"037\", \"065\", \"059\", \"071\", \"073\", \"083\", \"111\", \"079\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline \n",
    "# goal: census tract daily dataset with exposure (yes/no) based on various buffers (specified below)\n",
    "# steps:\n",
    "    # 1. download fires data\n",
    "    # 2. load census tract data\n",
    "    # 3. load wf boundary data\n",
    "    # 4. create merged fire polys (agg over days)\n",
    "    # 5. buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "    # 6. overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "    # 7. final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: download fires data\n",
    "\n",
    "# generate a filename with the current date\n",
    "filename = f\"data_{datetime.now().strftime('%Y_%m_%d')}.geojson\"\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful\n",
    "response.raise_for_status()  \n",
    "\n",
    "# Save\n",
    "with open(output_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 2-3: load and clean fires and cts data \n",
    "\n",
    "# data contains wf data going back to 2024 or 2023 \n",
    "# filter to dates since January 7th, 2025 and take out time\n",
    "fires = gpd.read_file(output_path).to_crs(epsg=2229)\n",
    "cts = gpd.read_file(data_dir / \"00_raw/tl_2010_06_tract10.shp\").to_crs(epsg=2229)\n",
    "cts = cts[['geometry', 'GEOID10', 'COUNTYFP10']]\n",
    "cts = cts[cts['COUNTYFP10'].isin(so_cal_counties)]\n",
    "\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.tz_convert('US/Pacific')\n",
    "fires = fires[fires['poly_DateCurrent'] > '2025-01-06']\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.date\n",
    "\n",
    "# fill in names for all fires \n",
    "fires[\"incident_name\"] = fires[\"incident_name\"].str.lower()\n",
    "fires['incident_name'].fillna(fires['mission'].str.split('-').str[2].str.lower(), inplace=True)\n",
    "\n",
    "# filter to only the cols we need\n",
    "# incident_name, poly_DateCurrent, geometry\n",
    "fires = fires[[\"incident_name\", \"poly_DateCurrent\", \"geometry\"]]\n",
    "\n",
    "# NOTE: there is one row that is called kenneth but has a poly that covers both pallisades and kenneth. from jan 9\n",
    "# leaving it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: create merged fire polys (agg over days)\n",
    "# step 5: buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "# step 6: overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "# step 7: final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km\n",
    "buffer_distances = [0.5, 1, 10, 20]\n",
    "buffers = [500, 1_000, 10_000, 20_000]\n",
    "\n",
    "# Create empty dictionary to store results\n",
    "tract_exposures = {}\n",
    "# Create list to store summary table\n",
    "summary_data = []\n",
    "\n",
    "# For each buffer distance\n",
    "for dist, dist_km in zip(buffers, buffer_distances):\n",
    "    buffered_fires = fires.geometry.buffer(dist)\n",
    "    combined_buffer = buffered_fires.unary_union\n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "    num_exposed = len(exposed_tracts)\n",
    "    \n",
    "    summary_data.append({\n",
    "        'buffer_distance_km': dist_km,\n",
    "        'num_exposed_tracts': num_exposed,\n",
    "        'pct_exposed': round((num_exposed / len(cts))*100, 2)\n",
    "    })\n",
    "    \n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "    tract_exposures[f'exposed_{dist_km}buffer'] = exposed_tracts['GEOID10'].tolist()\n",
    "\n",
    "result_df = pd.DataFrame({'GEOID10': cts['GEOID10']})\n",
    "result_df = result_df.set_index('GEOID10')\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# add exposure columns\n",
    "for col in tract_exposures.keys():\n",
    "    result_df[col] = result_df.index.isin(tract_exposures[col]).astype(int)\n",
    "\n",
    "# save data!\n",
    "result_df.to_csv(data_dir / f\"02_processed/ct_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\")\n",
    "summary_df.to_csv(data_dir / f\"03_summaries/ct_summary_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting! \n",
    "\n",
    "fires = fires.to_crs(epsg=3857)\n",
    "merged_gdf = cts.merge(result_df, on='GEOID10', how='left').to_crs(epsg=3857)\n",
    "merged_gdf = merged_gdf[merged_gdf['GEOID10'] != '06037599100'] # get rid of islands\n",
    "\n",
    "buffer_vars = ['exposed_0.5buffer', 'exposed_1buffer', 'exposed_10buffer', 'exposed_20buffer']\n",
    "\n",
    "# get the bounds from the 20km buffer data only\n",
    "buffer_20km_bounds = merged_gdf[merged_gdf['exposed_20buffer'] == 1].total_bounds\n",
    "x_min, y_min, x_max, y_max = buffer_20km_bounds\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "fig.suptitle('Census tract exposure data by buffer size', fontsize=16)\n",
    "\n",
    "# plot each buffer var\n",
    "for idx, buffer_var in enumerate(buffer_vars):\n",
    "    ax = axes.flatten()[idx]\n",
    "    merged_gdf[merged_gdf[buffer_var] == 1].plot(\n",
    "        ax=ax,\n",
    "        edgecolor='grey',\n",
    "        color='lightblue',\n",
    "        alpha=0.7,\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    fires.boundary.plot(ax=ax, color=\"red\", linewidth=.4)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_title(f'{buffer_var}')\n",
    "    ax.axis('off')\n",
    "    cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
