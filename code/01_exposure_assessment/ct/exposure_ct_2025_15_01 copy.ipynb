{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import contextily as cx\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "root_dir = Path(\"~/Desktop/Desktop/epidemiology_PhD/00_repos/\").expanduser()\n",
    "\n",
    "url = \"https://hub.arcgis.com/api/v3/datasets/025fb2ea05f14890b2b11573341b5b18_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1\"\n",
    "\n",
    "output_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data/calfire_boundaries\"\n",
    "data_dir = root_dir / \"los_angeles_2025_fire_disasters_exp/data\"\n",
    "\n",
    "so_cal_counties = [\"025\", \"029\", \"037\", \"065\", \"059\", \"071\", \"073\", \"083\", \"111\", \"079\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline \n",
    "# goal: census tract daily dataset with exposure (yes/no) based on various buffers (specified below)\n",
    "# steps:\n",
    "    # 1. download fires data\n",
    "    # 2. load census tract data\n",
    "    # 3. load wf boundary data\n",
    "    # 4. create merged fire polys (agg over days)\n",
    "    # 5. buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "    # 6. overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "    # 7. final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: download fires data\n",
    "\n",
    "# generate a filename with the current date\n",
    "filename = f\"data_{datetime.now().strftime('%Y_%m_%d')}.geojson\"\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful\n",
    "response.raise_for_status()  \n",
    "\n",
    "# Save\n",
    "with open(output_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 2-3: load and clean fires and cts data \n",
    "\n",
    "# data contains wf data going back to 2024 or 2023 \n",
    "# filter to dates since January 7th, 2025 and take out time\n",
    "fires = gpd.read_file(output_path).to_crs(epsg=2229)\n",
    "cts = gpd.read_file(data_dir / \"tl_2010_06_tract10.shp\").to_crs(epsg=2229)\n",
    "cts = cts[['geometry', 'GEOID10', 'COUNTYFP10']]\n",
    "cts = cts[cts['COUNTYFP10'].isin(so_cal_counties)]\n",
    "\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.tz_convert('US/Pacific')\n",
    "fires = fires[fires['poly_DateCurrent'] > '2025-01-06']\n",
    "fires[\"poly_DateCurrent\"] = fires[\"poly_DateCurrent\"].dt.date\n",
    "\n",
    "# fill in names for all fires \n",
    "fires[\"incident_name\"] = fires[\"incident_name\"].str.lower()\n",
    "fires['incident_name'].fillna(fires['mission'].str.split('-').str[2].str.lower(), inplace=True)\n",
    "\n",
    "# filter to only the cols we need\n",
    "# incident_name, poly_DateCurrent, geometry\n",
    "fires = fires[[\"incident_name\", \"poly_DateCurrent\", \"geometry\"]]\n",
    "\n",
    "# NOTE: there is one row that is called kenneth but has a poly that covers both pallisades and kenneth. from jan 9\n",
    "# leaving it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: create merged fire polys (agg over days)\n",
    "# step 5: buffer the fire polys (buffers: .5, 1, 10, 20 km)\n",
    "# step 6: overlay each buffer version with census tracts to determine if there is any overlap (any overlap at all = exposed)\n",
    "# step 7: final dataset: census_tract, exposed_0.5km, exposed_1km, exposed_10km, exposed_20km\n",
    "buffer_distances = [0.5, 1, 10, 20]\n",
    "buffers = [500, 1_000, 10_000, 20_000]\n",
    "\n",
    "# Create empty dictionary to store results\n",
    "tract_exposures = {}\n",
    "# Create list to store summary table\n",
    "summary_data = []\n",
    "\n",
    "# For each buffer distance\n",
    "for dist, dist_km in zip(buffers, buffer_distances):\n",
    "    # Create buffer\n",
    "    buffered_fires = fires.geometry.buffer(dist)\n",
    "    \n",
    "    # Dissolve all fire buffers into single geometry\n",
    "    combined_buffer = buffered_fires.unary_union\n",
    "\n",
    "    # Count exposed tracts\n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "    num_exposed = len(exposed_tracts)\n",
    "    \n",
    "    # Store in our list\n",
    "    summary_data.append({\n",
    "        'buffer_distance_km': dist_km,\n",
    "        'num_exposed_tracts': num_exposed\n",
    "    })\n",
    "    \n",
    "    # Spatial join with census tracts\n",
    "    exposed_tracts = cts[cts.geometry.intersects(combined_buffer)]\n",
    "        \n",
    "    # Store tract GEOIDs for this buffer distance\n",
    "    tract_exposures[f'exposed_{dist_km}buffer'] = exposed_tracts['GEOID10'].tolist()\n",
    "\n",
    "# Create final dataframe\n",
    "result_df = pd.DataFrame({'GEOID10': cts['GEOID10']})\n",
    "result_df = result_df.set_index('GEOID10')\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Add exposure columns\n",
    "for col in tract_exposures.keys():\n",
    "    result_df[col] = result_df.index.isin(tract_exposures[col]).astype(int)\n",
    "\n",
    "# Write out data\n",
    "result_df.to_csv(data_dir / f\"ct_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\")\n",
    "summary_df.to_csv(data_dir / f\"ct_summary_exposures_{datetime.now().strftime('%Y_%m_%d')}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index(inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = fires.to_crs(epsg=3857)\n",
    "merged_gdf = cts.merge(result_df, on='GEOID10', how='left').to_crs(epsg=3857)\n",
    "merged_gdf = merged_gdf[merged_gdf['GEOID10'] != '06037599100'] # get rid of islands\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "fig.suptitle('Buffer Analysis by Census Tract', fontsize=16)\n",
    "\n",
    "# Buffer variables to map\n",
    "buffer_vars = ['exposed_0.5buffer', 'exposed_1buffer', 'exposed_10buffer', 'exposed_20buffer']\n",
    "\n",
    "# Get the bounds from the 20km buffer data only\n",
    "buffer_20km_bounds = merged_gdf[merged_gdf['exposed_20buffer'] == 1].total_bounds\n",
    "x_min, y_min, x_max, y_max = buffer_20km_bounds\n",
    "\n",
    "# Plot each buffer variable\n",
    "for idx, buffer_var in enumerate(buffer_vars):\n",
    "    # Get axis (convert from 2D to 1D indexing)\n",
    "    ax = axes.flatten()[idx]\n",
    "    \n",
    "    # Plot only tracts where buffer = 1\n",
    "    merged_gdf[merged_gdf[buffer_var] == 1].plot(\n",
    "        ax=ax,\n",
    "        edgecolor='grey',\n",
    "        color='lightblue',\n",
    "        alpha=0.7,\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "    fires.boundary.plot(ax=ax, color=\"red\", linewidth=.4)\n",
    "    \n",
    "    # Set consistent bounds from 20km buffer for all subplots\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    \n",
    "    ax.set_title(f'{buffer_var}')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the coastal and island tracts that have no people in the future. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la_fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
